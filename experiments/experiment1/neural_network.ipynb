{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 1.2.1, GPU: Not found\n"
     ]
    }
   ],
   "source": [
    "import pandas_datareader.data as pdr\n",
    "import datetime\n",
    "import numpy as np\n",
    "import unittest\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# seems to be a problem with pandas_datareader\n",
    "# use this fix to get data from Yahoo! Finance\n",
    "import fix_yahoo_finance as yf\n",
    "yf.pdr_override()\n",
    "\n",
    "# import tensorflow and print info\n",
    "import tensorflow as tf\n",
    "gpu_info = \"Not found\" if not tf.test.gpu_device_name() else tf.test.gpu_device_name() \n",
    "print(\"Tensorflow version %s, GPU: %s\" % (tf.__version__,gpu_info))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_unit_tests(testClass):\n",
    "    suite = unittest.TestLoader().loadTestsFromTestCase(testClass)\n",
    "    unittest.TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Create a class that downloads the stock data and sets up the input/output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CreateDataSet:\n",
    "    \n",
    "    def __init__(self,symbol,number_of_days=10):\n",
    "        self.symbol = symbol\n",
    "        self.number_of_days = number_of_days\n",
    "        self.train_start_date = None\n",
    "        self.train_end_date = None\n",
    "        self.test_start_date = None\n",
    "        self.test_end_date = None\n",
    "        self.validation_start_date = None\n",
    "        self.validation_end_date = None\n",
    "        self.yahoo_data = None\n",
    "        self.pandas_df = None\n",
    "        self.training_df = None\n",
    "        self.test_df = None\n",
    "        self.validation_df = None\n",
    "        self.training_x = None\n",
    "        self.training_y = None\n",
    "        self.test_x = None\n",
    "        self.test_y = None\n",
    "        self.validation_x = None\n",
    "        self.validation_y = None\n",
    "        self.batch_size = None\n",
    "\n",
    "        \n",
    "    def set_training_dates(self,start_date,end_date):\n",
    "        self.__check_date_string_format(start_date)\n",
    "        self.__check_date_string_format(end_date)\n",
    "        self.__check_start_date_before_end_date(start_date,end_date)\n",
    "        self.train_start_date = start_date\n",
    "        self.train_end_date = end_date\n",
    "        \n",
    "    def set_test_dates(self,start_date,end_date):\n",
    "        self.__check_date_string_format(start_date)\n",
    "        self.__check_date_string_format(end_date)\n",
    "        self.__check_start_date_before_end_date(start_date,end_date)\n",
    "        self.test_start_date = start_date\n",
    "        self.test_end_date = end_date\n",
    "        \n",
    "    def set_validation_dates(self,start_date,end_date):\n",
    "        self.__check_date_string_format(start_date)\n",
    "        self.__check_date_string_format(end_date)\n",
    "        self.__check_start_date_before_end_date(start_date,end_date)\n",
    "        self.validation_start_date = start_date\n",
    "        self.validation_end_date = end_date\n",
    "        \n",
    "    def set_batch_size(self,batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def download_data(self):\n",
    "        assert self.train_start_date != None, \"Training start date not set\"\n",
    "        assert self.train_end_date != None, \"Training end date not set\"\n",
    "        assert self.test_start_date != None, \"Test start date not set\"\n",
    "        assert self.test_end_date != None, \"Test end date not set\"\n",
    "        assert self.validation_start_date != None, \"Validation start date not set\"\n",
    "        assert self.validation_end_date != None, \"Validation end date not set\"\n",
    "        \n",
    "        start_date, end_date = self.__calculate_download_start_end_dates()\n",
    "\n",
    "        self.yahoo_data = self.__download_data_yahoo(self.symbol,start_date,end_date)\n",
    "        \n",
    "        assert self.yahoo_data.shape != (0,0), \"No data was downloaded\"\n",
    "        \n",
    "    def create_dataset(self):\n",
    "        \n",
    "        if self.yahoo_data == None:\n",
    "            self.download_data()\n",
    "        \n",
    "        prices = self.yahoo_data['Adj Close']\n",
    "        \n",
    "        # fill in missing data\n",
    "        prices.fillna(method='ffill', inplace=True)\n",
    "        prices.fillna(method='bfill', inplace=True)\n",
    "        \n",
    "        # scale features to make neural network easier to train\n",
    "        scaled_prices = self.__scale_data(prices)\n",
    "        \n",
    "        # input features named X0, X1, X2, ...\n",
    "        # output feature named Y (this is what we are predicting, tomorrows stock price)\n",
    "        x_features = [ 'X%d' % (i) for i in range(self.number_of_days)]\n",
    "        y_feature = ['Y']\n",
    "        features = x_features + y_feature\n",
    "        \n",
    "        df = pd.DataFrame(index=prices.index,columns=features)\n",
    "        df['Y'] = scaled_prices.shift(-1)\n",
    "        \n",
    "        for i in range(self.number_of_days):\n",
    "            x_feature = \"X%d\" % (i)\n",
    "            df[x_feature] = scaled_prices.shift(i)\n",
    "            \n",
    "        # trim the dataset to only use dates with enough data\n",
    "        #\n",
    "        # example: if number_of_days=10, then first date with enough\n",
    "        # information will be day 10 (i.e. array index 9)\n",
    "        #\n",
    "        # last date will be next to last day in dataset since predicting tommorrows price\n",
    "        df = df[self.number_of_days-1:-1]\n",
    "        \n",
    "        # there shouldn't be any NaN values\n",
    "        assert df.isnull().values.any() == False, \"Dataset contains unexpected NaN values\"\n",
    "                    \n",
    "        self.pandas_df = df\n",
    "        \n",
    "        # split dataset into training/test/validation sets\n",
    "        \n",
    "        # data as pandas dataframes\n",
    "        self.training_df = df[self.train_start_date:self.train_end_date]\n",
    "        self.test_df = df[self.test_start_date:self.test_end_date]\n",
    "        self.validation_df = df[self.validation_start_date:self.validation_end_date]\n",
    "        \n",
    "        # data as numpy arrays\n",
    "        self.training_x = self.training_df[x_features].values\n",
    "        self.training_y = self.training_df[y_feature].values\n",
    "        self.test_x = self.test_df[x_features].values\n",
    "        self.test_y = self.test_df[y_feature].values\n",
    "        self.validation_x = self.validation_df[x_features].values\n",
    "        self.validation_y = self.validation_df[y_feature].values\n",
    "        \n",
    "    # function used with neural networks\n",
    "    # training happens on a batch instead of all the data\n",
    "    # this function is called multiple times using an iterator to get the next batch\n",
    "    def get_batches(self):\n",
    "        assert self.batch_size != None\n",
    "        \n",
    "        n_batches = len(self.training_x) // self.batch_size\n",
    "        assert n_batches > 0, \"Batch size %d is too big (resulted in 0 batches)\" % (self.batch_size)\n",
    "        \n",
    "        x = self.training_x[:n_batches*self.batch_size]\n",
    "        y = self.training_y[:n_batches*self.batch_size]\n",
    "        \n",
    "        for ii in range(0, len(x), self.batch_size):\n",
    "            yield x[ii:ii+self.batch_size], y[ii:ii+self.batch_size]\n",
    "        \n",
    "    def __download_data_yahoo(self,symbol,start_date,end_date):\n",
    "        data = pdr.get_data_yahoo(symbol, start=start_date, end=end_date)\n",
    "        return data\n",
    "    \n",
    "    def __str_to_datetime(self,date_str):\n",
    "        return datetime.datetime.strptime(date_str,\"%Y-%m-%d\")\n",
    "    \n",
    "    def __check_date_string_format(self,date_str):\n",
    "        assert datetime.datetime.strptime(date_str,\"%Y-%m-%d\"), \"Dates must be a string in the format YYYY-MM-DD\"\n",
    "        \n",
    "    def __check_start_date_before_end_date(self,start_date,end_date):\n",
    "        start = self.__str_to_datetime(start_date)\n",
    "        end = self.__str_to_datetime(end_date)\n",
    "        assert start < end, \"Start date must be before the end date\"\n",
    "        \n",
    "    def __calculate_download_start_end_dates(self):\n",
    "        train_start = self.__str_to_datetime(self.train_start_date)\n",
    "        test_start = self.__str_to_datetime(self.test_start_date)\n",
    "        validation_start = self.__str_to_datetime(self.validation_start_date)\n",
    "        train_end = self.__str_to_datetime(self.train_end_date)\n",
    "        test_end = self.__str_to_datetime(self.test_end_date)\n",
    "        validation_end = self.__str_to_datetime(self.validation_end_date)\n",
    "        \n",
    "        start_datetime = min(train_start,test_start,validation_start)\n",
    "        end_datetime = max(train_end,test_end,validation_end)\n",
    "        \n",
    "        start_date = start_datetime.strftime(\"%Y-%m-%d\")\n",
    "        end_date = end_datetime.strftime(\"%Y-%m-%d\")\n",
    "          \n",
    "        return start_date,end_date\n",
    "    \n",
    "    def __scale_data(self,data):\n",
    "        mean, std = data.mean(), data.std()\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        \n",
    "        scaled_data = (data - mean) / std\n",
    "        return scaled_data\n",
    "    \n",
    "    def unscale_data(self,scaled_data):\n",
    "        return scaled_data * self.std + self.mean\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 9 tests in 2.116s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Test the create data set class\n",
    "class CreateDataSetTest(unittest.TestCase):\n",
    "        \n",
    "    def test_set_dates(self):\n",
    "        dataset = CreateDataSet('SPY')\n",
    "        dataset.set_training_dates(start_date=\"2010-01-01\",end_date=\"2011-01-01\")\n",
    "        dataset.set_test_dates(start_date=\"2010-01-01\",end_date=\"2011-01-01\")\n",
    "        dataset.set_validation_dates(start_date=\"2010-01-01\",end_date=\"2011-01-01\")\n",
    "        \n",
    "    def test_set_dates_not_str(self):\n",
    "        dataset = CreateDataSet('SPY')\n",
    "        \n",
    "        with self.assertRaises(Exception):\n",
    "            dataset.set_training_dates(start_date=datetime.datetime(2010,1,1),end_date=\"2011-01-01\")\n",
    "            \n",
    "        with self.assertRaises(Exception):\n",
    "            dataset.set_training_dates(start_date=\"2010-01-01\",end_date=datetime.datetime(2011,1,1))\n",
    "            \n",
    "        with self.assertRaises(Exception):\n",
    "            dataset.set_test_dates(start_date=datetime.datetime(2010,1,1),end_date=\"2011-01-01\")\n",
    "            \n",
    "        with self.assertRaises(Exception):\n",
    "            dataset.set_test_dates(start_date=\"2010-01-01\",end_date=datetime.datetime(2011,1,1))\n",
    "            \n",
    "        with self.assertRaises(Exception):\n",
    "            dataset.set_validation_dates(start_date=datetime.datetime(2010,1,1),end_date=\"2011-01-01\")\n",
    "            \n",
    "        with self.assertRaises(Exception):\n",
    "            dataset.set_validation_dates(start_date=\"2010-01-01\",end_date=datetime.datetime(2011,1,1))\n",
    "            \n",
    "    def test_set_dates_bad_str_format(self):\n",
    "        dataset = CreateDataSet('SPY')\n",
    "        \n",
    "        with self.assertRaises(Exception):\n",
    "            dataset.set_training_dates(start_date=\"01-01-2011\",end_date=\"2011-01-01\")\n",
    "            \n",
    "        with self.assertRaises(Exception):\n",
    "            dataset.set_training_dates(start_date=\"2010-01-01\",end_date=\"01-01-2011\")\n",
    "            \n",
    "        with self.assertRaises(Exception):\n",
    "            dataset.set_test_dates(start_date=\"01-01-2011\",end_date=\"2011-01-01\")\n",
    "            \n",
    "        with self.assertRaises(Exception):\n",
    "            dataset.set_test_dates(start_date=\"2010-01-01\",end_date=\"01-01-2011\")\n",
    "            \n",
    "        with self.assertRaises(Exception):\n",
    "            dataset.set_validation_dates(start_date=\"01-01-2011\",end_date=\"2011-01-01\")\n",
    "            \n",
    "        with self.assertRaises(Exception):\n",
    "            dataset.set_validation_dates(start_date=\"2010-01-01\",end_date=\"01-01-2011\")\n",
    "            \n",
    "    def test_set_dates_start_date_after_end_date(self):\n",
    "        dataset = CreateDataSet('SPY')\n",
    "        \n",
    "        with self.assertRaises(Exception):\n",
    "            dataset.set_training_dates(start_date=\"2011-01-02\",end_date=\"2011-01-01\")\n",
    "            \n",
    "        with self.assertRaises(Exception):\n",
    "            dataset.set_test_dates(start_date=\"2011-01-02\",end_date=\"2011-01-01\")\n",
    "            \n",
    "        with self.assertRaises(Exception):\n",
    "            dataset.set_validation_dates(start_date=\"2011-01-02\",end_date=\"2011-01-01\")\n",
    "            \n",
    "    def test_download_start_end_dates_1(self):\n",
    "        dataset = CreateDataSet('SPY')\n",
    "        dataset.set_training_dates(start_date=\"2010-01-04\",end_date=\"2010-06-01\")\n",
    "        dataset.set_test_dates(start_date=\"2011-01-04\",end_date=\"2011-06-01\")\n",
    "        dataset.set_validation_dates(start_date=\"2012-01-04\",end_date=\"2012-06-01\")        \n",
    "        dataset.download_data()\n",
    "        \n",
    "        # (start_date,end_date) should be (training_start,validation_end)\n",
    "        self.__verify_start_end_date(dataset.yahoo_data,expected_start=\"2010-01-04\",expected_end=\"2012-06-01\")\n",
    "        \n",
    "    def test_download_start_end_dates_2(self):\n",
    "        dataset = CreateDataSet('SPY')\n",
    "        dataset.set_test_dates(start_date=\"2010-01-04\",end_date=\"2010-06-01\")\n",
    "        dataset.set_validation_dates(start_date=\"2011-01-04\",end_date=\"2011-06-01\")\n",
    "        dataset.set_training_dates(start_date=\"2012-01-04\",end_date=\"2012-06-01\")        \n",
    "        dataset.download_data()\n",
    "        \n",
    "        # (start_date,end_date) should be (test_start,training_end)\n",
    "        self.__verify_start_end_date(dataset.yahoo_data,expected_start=\"2010-01-04\",expected_end=\"2012-06-01\")\n",
    "        \n",
    "    def test_download_start_end_dates_3(self):\n",
    "        dataset = CreateDataSet('SPY')\n",
    "        dataset.set_validation_dates(start_date=\"2010-01-04\",end_date=\"2010-06-01\")\n",
    "        dataset.set_training_dates(start_date=\"2011-01-04\",end_date=\"2011-06-01\")\n",
    "        dataset.set_test_dates(start_date=\"2012-01-04\",end_date=\"2012-06-01\")        \n",
    "        dataset.download_data()\n",
    "        \n",
    "        # (start_date,end_date) should be (validation_start,test_end)\n",
    "        self.__verify_start_end_date(dataset.yahoo_data,expected_start=\"2010-01-04\",expected_end=\"2012-06-01\")\n",
    "        \n",
    "    def __verify_start_end_date(self,dataframe,expected_start,expected_end):\n",
    "        start_date, end_date = dataframe.index[0], dataframe.index[-1]\n",
    "        start_date = start_date.strftime(\"%Y-%m-%d\")\n",
    "        end_date = end_date.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        self.assertEqual(start_date,expected_start)\n",
    "        self.assertEqual(end_date,expected_end)\n",
    "        \n",
    "    def test_create_dataset(self):\n",
    "        dataset = CreateDataSet('SPY')\n",
    "        dataset.set_training_dates(start_date=\"2010-01-04\",end_date=\"2010-06-01\")\n",
    "        dataset.set_test_dates(start_date=\"2011-01-04\",end_date=\"2011-06-01\")\n",
    "        dataset.set_validation_dates(start_date=\"2012-01-04\",end_date=\"2012-06-01\")        \n",
    "        dataset.create_dataset()\n",
    "        \n",
    "        # check for 10 x features and 1 y feature\n",
    "        self.assertEqual(dataset.training_x.shape[1],10)\n",
    "        self.assertEqual(dataset.training_y.shape[1],1)\n",
    "        self.assertEqual(dataset.test_x.shape[1],10)\n",
    "        self.assertEqual(dataset.test_y.shape[1],1)\n",
    "        self.assertEqual(dataset.validation_x.shape[1],10)\n",
    "        self.assertEqual(dataset.validation_y.shape[1],1)\n",
    "        \n",
    "        # check dates\n",
    "        self.__check_data_in_date_range(dataset.training_df,start_date=\"2010-01-04\",end_date=\"2010-06-01\")\n",
    "        self.__check_data_in_date_range(dataset.test_df,start_date=\"2011-01-04\",end_date=\"2011-06-01\")\n",
    "        self.__check_data_in_date_range(dataset.validation_df,start_date=\"2012-01-04\",end_date=\"2012-06-01\")\n",
    "        \n",
    "    def __check_data_in_date_range(self,df,start_date,end_date):\n",
    "        dates = df.index\n",
    "        start_timestamp = pd.to_datetime(start_date)        \n",
    "        end_timestamp = pd.to_datetime(end_date)\n",
    "        \n",
    "        for date in dates:\n",
    "            self.assertTrue(date >= start_timestamp)\n",
    "            self.assertTrue(date <= end_timestamp)\n",
    "            \n",
    "    def test_get_batches(self):\n",
    "        dataset = CreateDataSet('SPY')\n",
    "        dataset.set_training_dates(start_date=\"2010-01-04\",end_date=\"2010-06-01\")\n",
    "        dataset.set_test_dates(start_date=\"2011-01-04\",end_date=\"2011-06-01\")\n",
    "        dataset.set_validation_dates(start_date=\"2012-01-04\",end_date=\"2012-06-01\")        \n",
    "        dataset.create_dataset()\n",
    "        \n",
    "        dataset.set_batch_size(32)\n",
    "        for x_batch, y_batch in dataset.get_batches():\n",
    "            self.assertEqual(x_batch.shape,(32,10))\n",
    "            self.assertEqual(y_batch.shape,(32,1))\n",
    "            \n",
    "    \n",
    "        \n",
    "run_unit_tests(CreateDataSetTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your model\n",
    "Setup whatever model you plan to use for price prediction. i.e. neural network, linear regression, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Brent/anaconda/envs/stocks/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.learning_rate = None\n",
    "        self.number_of_inputs = None\n",
    "        self.keep_prob = None\n",
    "        self.hidden_layers = []\n",
    "        \n",
    "    def add_inputs(self,number_of_inputs):\n",
    "        self.number_of_inputs = number_of_inputs\n",
    "        \n",
    "    def add_hidden_layer(self,number_of_nodes,dropout=False):\n",
    "        self.hidden_layers.append((number_of_nodes,dropout))\n",
    "            \n",
    "    def set_learning_rate(self,learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def set_keep_probability(self,keep_prob):\n",
    "        self.keep_prob = keep_prob\n",
    "        \n",
    "    def build_model(self):\n",
    "        \n",
    "        inputs_ = tf.placeholder(tf.float32,[None,self.number_of_inputs],name=\"inputs\")\n",
    "        targets_ = tf.placeholder(tf.float32,[None,1],name=\"targets\")\n",
    "        keep_prob = tf.placeholder(tf.float32,name=\"keep_prob\")\n",
    "        \n",
    "        # add hidden layers\n",
    "        layer = inputs_\n",
    "        for i in range(len(self.hidden_layers)):\n",
    "            num_nodes, dropout = self.hidden_layers[i]\n",
    "\n",
    "            layer = tf.layers.dense(layer,num_nodes,activation=tf.nn.relu)\n",
    "            \n",
    "            if dropout:\n",
    "                layer = tf.nn.dropout(layer,keep_prob)\n",
    "            \n",
    "            \n",
    "        # last layer predict the price\n",
    "        output = tf.layers.dense(layer,1,activation=None,name=\"output\")\n",
    "        \n",
    "        # setup loss function and optimizer\n",
    "        loss = tf.nn.l2_loss(targets_-output)\n",
    "        cost = tf.reduce_mean(loss)\n",
    "        opt = tf.train.AdamOptimizer(self.learning_rate).minimize(cost)\n",
    "\n",
    "nn = NeuralNetwork()\n",
    "nn.set_learning_rate(.001)\n",
    "nn.set_keep_probability(0.5)\n",
    "nn.add_inputs(number_of_inputs=10)\n",
    "nn.add_hidden_layer(number_of_nodes=20)\n",
    "nn.build_model()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your model\n",
    "Define the function to train your model using the training data and the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model,train_data,test_data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate your model on the validation set\n",
    "Return the accuracy of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model,validation_data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the results\n",
    "Show graphs and metrics of your model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def results():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate your model here\n",
    "Call the functions to get the data, train the model, and evaluate it on the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
